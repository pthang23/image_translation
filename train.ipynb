{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aDJ-OsdNRTDX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704198362467,
     "user_tz": -420,
     "elapsed": 5491,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-01-04T16:49:09.035851431Z",
     "start_time": "2024-01-04T16:49:06.646155319Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 22\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m defaultdict\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OrderedDict\n\u001B[0;32m---> 22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m optim\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import json\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as font_manager\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from PIL import Image\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fIdVJTb11s0I",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704198364987,
     "user_tz": -420,
     "elapsed": 2542,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     }
    },
    "outputId": "ad9b380a-d976-4a99-a56b-8554c9b8800a"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content/gdrive/My Drive/FA23_DatTriQuynh/Code"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iG2bfEkq1tso",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704198364988,
     "user_tz": -420,
     "elapsed": 17,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     }
    },
    "outputId": "a353f725-4d28-4709-8b81-a5a9502868fa"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/gdrive/.shortcut-targets-by-id/1POdiPpRQ9jOyxG747glU_7Umrq_XkMmg/FA23_DatTriQuynh/Code\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install pyquaternion\n",
    "!pip install nuscenes-devkit\n",
    "!pip install ipykernel\n",
    "!python -m ipykernel install\n",
    "\n",
    "!module load deeplearning/2.10.1\n",
    "!pip install pyquaternion shapely lmdb opencv-python nuscenes-devkit\n",
    "\n",
    "!pip install Pillow\n",
    "!pip install lmdb==1.3.0"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEbmYxQc1wes",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704198393138,
     "user_tz": -420,
     "elapsed": 28160,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     }
    },
    "outputId": "e7de85bf-18ee-4da8-bccb-d7e7fbbfe679"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.10/dist-packages (0.9.9)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyquaternion) (1.23.5)\n",
      "Requirement already satisfied: nuscenes-devkit in /usr/local/lib/python3.10/dist-packages (1.1.11)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (5.3.2)\n",
      "Requirement already satisfied: descartes in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (1.1.0)\n",
      "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (0.5.0)\n",
      "Requirement already satisfied: matplotlib<3.6.0 in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (1.23.5)\n",
      "Requirement already satisfied: opencv-python>=4.5.4.58 in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (4.8.0.76)\n",
      "Requirement already satisfied: Pillow>6.2.1 in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (9.4.0)\n",
      "Requirement already satisfied: pyquaternion>=0.9.5 in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (0.9.9)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (1.11.4)\n",
      "Requirement already satisfied: Shapely<2.0.0 in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (1.8.5.post1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (4.66.1)\n",
      "Requirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (2.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6.0->nuscenes-devkit) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6.0->nuscenes-devkit) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6.0->nuscenes-devkit) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6.0->nuscenes-devkit) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6.0->nuscenes-devkit) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6.0->nuscenes-devkit) (2.8.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->nuscenes-devkit) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->nuscenes-devkit) (2.4.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nuscenes-devkit) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nuscenes-devkit) (3.2.0)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (5.5.6)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel) (0.2.0)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (7.34.0)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.7.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.1.12)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.3.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (67.7.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (3.0.43)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (2.16.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel) (5.5.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel) (23.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel) (2.8.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel) (4.1.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel) (0.2.12)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel) (1.16.0)\n",
      "Installed kernelspec python3 in /usr/local/share/jupyter/kernels/python3\n",
      "/bin/bash: line 1: module: command not found\n",
      "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.10/dist-packages (0.9.9)\n",
      "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (1.8.5.post1)\n",
      "Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
      "Requirement already satisfied: nuscenes-devkit in /usr/local/lib/python3.10/dist-packages (1.1.11)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyquaternion) (1.23.5)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (5.3.2)\n",
      "Requirement already satisfied: descartes in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (1.1.0)\n",
      "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (0.5.0)\n",
      "Requirement already satisfied: matplotlib<3.6.0 in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (3.5.3)\n",
      "Requirement already satisfied: Pillow>6.2.1 in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (9.4.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (1.11.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (4.66.1)\n",
      "Requirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from nuscenes-devkit) (2.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6.0->nuscenes-devkit) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6.0->nuscenes-devkit) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6.0->nuscenes-devkit) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6.0->nuscenes-devkit) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6.0->nuscenes-devkit) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6.0->nuscenes-devkit) (2.8.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->nuscenes-devkit) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->nuscenes-devkit) (2.4.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nuscenes-devkit) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nuscenes-devkit) (3.2.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
      "Requirement already satisfied: lmdb==1.3.0 in /usr/local/lib/python3.10/dist-packages (1.3.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1571,
     "status": "ok",
     "timestamp": 1704198394703,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     },
     "user_tz": -420
    },
    "id": "crVzyl9WR2RZ"
   },
   "outputs": [],
   "source": [
    "import src\n",
    "import src.data.collate_funcs\n",
    "import src.model.network as networks\n",
    "\n",
    "from src.data.dataloader import nuScenesMaps\n",
    "from src.utils import MetricDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LGQmvG50UFpA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704198394704,
     "user_tz": -420,
     "elapsed": 34,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     }
    }
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"font.family\"] = \"serif\"\n",
    "cmfont = font_manager.FontProperties(fname=mpl.get_data_path() + \"/fonts/ttf/cmr10.ttf\")\n",
    "mpl.rcParams[\"font.serif\"] = cmfont.get_name()\n",
    "mpl.rcParams[\"mathtext.fontset\"] = \"cm\"\n",
    "mpl.rcParams[\"axes.unicode_minus\"] = False\n",
    "plt.rcParams[\"axes.grid\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vf1I00B1UKkv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704198394704,
     "user_tz": -420,
     "elapsed": 29,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     }
    }
   },
   "outputs": [],
   "source": [
    "def train(args, dataloader, model, optimizer, epoch):\n",
    "    print(\"\\n==> Training on {} minibatches\".format(len(dataloader)))\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Calculate the memory used during the step\n",
    "    epoch_loss = MetricDict()\n",
    "    epoch_loss_per_class = MetricDict()\n",
    "    batch_acc_loss = MetricDict()\n",
    "    epoch_iou = MetricDict()\n",
    "    num_classes = len(args.pred_classes_nusc)\n",
    "\n",
    "    # Calculate the memory used during the step\n",
    "\n",
    "    for i, ((image, calib, grid2d), (cls_map, vis_mask)) in enumerate(dataloader):\n",
    "        # Move tensors to GPU\n",
    "        image, calib, cls_map, vis_mask, grid2d = (\n",
    "            image.cuda(),\n",
    "            calib.cuda(),\n",
    "            cls_map.cuda(),\n",
    "            vis_mask.cuda(),\n",
    "            grid2d.cuda(),\n",
    "        )\n",
    "\n",
    "        # Run network forwards\n",
    "        pred_ms = model(image, calib, grid2d)\n",
    "\n",
    "        # Convert ground truths to binary mask\n",
    "        gt_s1 = (cls_map > 0).float()\n",
    "        visibility_mask_s1 = (vis_mask > 0).float()\n",
    "\n",
    "        # Downsample to match model outputs\n",
    "        map_sizes = [pred.shape[-2:] for pred in pred_ms]\n",
    "        gt_ms = src.utils.downsample_gt(gt_s1, map_sizes)\n",
    "        vis_ms = src.utils.downsample_gt(visibility_mask_s1, map_sizes)\n",
    "\n",
    "        # Compute losses for backprop\n",
    "        loss, loss_dict = compute_loss(pred_ms, gt_ms, args.loss, args)\n",
    "\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Compute IoU\n",
    "        iou_per_sample, iou_dict = src.utils.compute_multiscale_iou(\n",
    "            pred_ms, gt_ms, vis_ms, num_classes\n",
    "        )\n",
    "        # Compute per class loss for eval\n",
    "        per_class_loss_dict = src.utils.compute_multiscale_loss_per_class(\n",
    "            pred_ms, gt_ms,\n",
    "        )\n",
    "\n",
    "        if float(loss) != float(loss):\n",
    "            raise RuntimeError(\"Loss diverged :(\")\n",
    "\n",
    "        epoch_loss += loss_dict\n",
    "        epoch_loss_per_class += per_class_loss_dict\n",
    "        batch_acc_loss += loss_dict\n",
    "        epoch_iou += iou_dict\n",
    "\n",
    "        if (i + 1) % args.accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Print summary\n",
    "            batch_time = (time.time() - t) / (1 if i == 0 else args.print_iter)\n",
    "            eta = ((args.epochs - epoch + 1) * len(dataloader) - i) * batch_time\n",
    "\n",
    "            s = \"[Epoch: {} {:4d}/{:4d}] batch_time: {:.2f}s eta: {:s} loss: \".format(\n",
    "                epoch, i, len(dataloader), batch_time, str(timedelta(seconds=int(eta)))\n",
    "            )\n",
    "            for k, v in batch_acc_loss.mean.items():\n",
    "                s += \"{}: {:.2e} \".format(k, v)\n",
    "\n",
    "            with open(os.path.join(args.savedir, args.name, \"output.txt\"), \"a\") as fp:\n",
    "                fp.write(s)\n",
    "            print(s)\n",
    "            t = time.time()\n",
    "\n",
    "            batch_acc_loss = MetricDict()\n",
    "\n",
    "    # Calculate per class IoUs over set\n",
    "    scales = [pred.shape[-1] for pred in pred_ms]\n",
    "    ms_cumsum_iou_per_class = torch.stack(\n",
    "        [epoch_iou[\"s{}_iou_per_class\".format(scale)] for scale in scales]\n",
    "    )\n",
    "    ms_count_per_class = torch.stack(\n",
    "        [epoch_iou[\"s{}_class_count\".format(scale)] for scale in scales]\n",
    "    )\n",
    "    ms_ious_per_class = (\n",
    "        (ms_cumsum_iou_per_class / (ms_count_per_class + 1)).cpu().numpy()\n",
    "    )\n",
    "    ms_mean_iou = ms_ious_per_class.mean(axis=1)\n",
    "\n",
    "    # Calculate per class loss over set\n",
    "    ms_cumsum_loss_per_class = torch.stack(\n",
    "        [epoch_loss_per_class[\"s{}_loss_per_class\".format(scale)] for scale in scales]\n",
    "    )\n",
    "    ms_loss_per_class = (\n",
    "        (ms_cumsum_loss_per_class / (ms_count_per_class + 1)).cpu().numpy()\n",
    "    )\n",
    "    total_loss = ms_loss_per_class.mean(axis=1).sum()\n",
    "\n",
    "    # Print epoch summary and save results\n",
    "    print(\"==> Training epoch complete\")\n",
    "    for key, value in epoch_loss.mean.items():\n",
    "        print(\"{:8s}: {:.4e}\".format(key, value))\n",
    "\n",
    "    with open(os.path.join(args.savedir, args.name, \"train_loss.txt\"), \"a\") as f:\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\n",
    "            \"{},\".format(epoch)\n",
    "            + \"{},\".format(float(total_loss))\n",
    "            + \"\".join(\"{},\".format(v) for v in ms_mean_iou)\n",
    "        )\n",
    "    with open(os.path.join(args.savedir, args.name, \"train_ious.txt\"), \"a\") as f:\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\n",
    "            \"Epoch: {}, \\n\".format(epoch)\n",
    "            + \"Total Loss: {}, \\n\".format(float(total_loss))\n",
    "            + \"\".join(\n",
    "                \"s{}_ious_per_class: {}, \\n\".format(s, v)\n",
    "                for s, v in zip(scales, ms_ious_per_class)\n",
    "            )\n",
    "            + \"\".join(\n",
    "                \"s{}_loss_per_class: {}, \\n\".format(s, v)\n",
    "                for s, v in zip(scales, ms_loss_per_class)\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "X1S8LqjrRGfa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704198394705,
     "user_tz": -420,
     "elapsed": 27,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     }
    }
   },
   "outputs": [],
   "source": [
    "def validate(args, dataloader, model, epoch):\n",
    "    print(\"\\n==> Validating on {} minibatches\\n\".format(len(dataloader)))\n",
    "    model.eval()\n",
    "    epoch_loss = MetricDict()\n",
    "    epoch_iou = MetricDict()\n",
    "    epoch_loss_per_class = MetricDict()\n",
    "    num_classes = len(args.pred_classes_nusc)\n",
    "    times = []\n",
    "\n",
    "    for i, ((image, calib, grid2d), (cls_map, vis_mask)) in enumerate(dataloader):\n",
    "        # Move tensors to GPU\n",
    "        image, calib, cls_map, vis_mask, grid2d = (\n",
    "            image.cuda(),\n",
    "            calib.cuda(),\n",
    "            cls_map.cuda(),\n",
    "            vis_mask.cuda(),\n",
    "            grid2d.cuda(),\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Run network forwards\n",
    "            pred_ms = model(image, calib, grid2d)\n",
    "\n",
    "            # Upsample largest prediction to 200x200\n",
    "            pred_200x200 = F.interpolate(\n",
    "                pred_ms[0], size=(200, 200), mode=\"bilinear\"\n",
    "            )\n",
    "            # pred_200x200 = (pred_200x200 > 0).float()\n",
    "            pred_ms = [pred_200x200, *pred_ms]\n",
    "\n",
    "            # Get required gt output sizes\n",
    "            map_sizes = [pred.shape[-2:] for pred in pred_ms]\n",
    "\n",
    "            # Convert ground truth to binary mask\n",
    "            gt_s1 = (cls_map > 0).float()\n",
    "            vis_mask_s1 = (vis_mask > 0.5).float()\n",
    "\n",
    "            # Downsample to match model outputs\n",
    "            gt_ms = src.utils.downsample_gt(gt_s1, map_sizes)\n",
    "            vis_ms = src.utils.downsample_gt(vis_mask_s1, map_sizes)\n",
    "\n",
    "            # Compute IoU\n",
    "            iou_per_sample, iou_dict = src.utils.compute_multiscale_iou(\n",
    "                pred_ms, gt_ms, vis_ms, num_classes\n",
    "            )\n",
    "            # Compute per class loss for eval\n",
    "            per_class_loss_dict = src.utils.compute_multiscale_loss_per_class(\n",
    "                pred_ms, gt_ms,\n",
    "            )\n",
    "\n",
    "            epoch_iou += iou_dict\n",
    "            epoch_loss_per_class += per_class_loss_dict\n",
    "\n",
    "            # Visualize predictions\n",
    "            # if epoch % args.val_interval * 4 == 0 and i % 50 == 0:\n",
    "            #     vis_img = ToPILImage()(image[0].detach().cpu())\n",
    "            #     pred_vis = pred_ms[1].detach().cpu()\n",
    "            #     label_vis = gt_ms[1]\n",
    "            #\n",
    "            #     # Visualize scores\n",
    "            #     vis_fig = visualize_score(\n",
    "            #         pred_vis[0],\n",
    "            #         label_vis[0],\n",
    "            #         grid2d[0],\n",
    "            #         vis_img,\n",
    "            #         iou_per_sample[0],\n",
    "            #         num_classes,\n",
    "            #     )\n",
    "            #     plt.savefig(\n",
    "            #         os.path.join(\n",
    "            #             args.savedir,\n",
    "            #             args.name,\n",
    "            #             \"val_output_epoch{}_iter{}.png\".format(epoch, i),\n",
    "            #         )\n",
    "            #     )\n",
    "\n",
    "    print(\"\\n==> Validation epoch complete\")\n",
    "\n",
    "    # Calculate per class IoUs over set\n",
    "    scales = [pred.shape[-1] for pred in pred_ms]\n",
    "\n",
    "    ms_cumsum_iou_per_class = torch.stack(\n",
    "        [epoch_iou[\"s{}_iou_per_class\".format(scale)] for scale in scales]\n",
    "    )\n",
    "    ms_count_per_class = torch.stack(\n",
    "        [epoch_iou[\"s{}_class_count\".format(scale)] for scale in scales]\n",
    "    )\n",
    "\n",
    "    ms_ious_per_class = (\n",
    "        (ms_cumsum_iou_per_class / (ms_count_per_class + 1e-6)).cpu().numpy()\n",
    "    )\n",
    "    ms_mean_iou = ms_ious_per_class.mean(axis=1)\n",
    "\n",
    "    # Calculate per class loss over set\n",
    "    ms_cumsum_loss_per_class = torch.stack(\n",
    "        [epoch_loss_per_class[\"s{}_loss_per_class\".format(scale)] for scale in scales]\n",
    "    )\n",
    "    ms_loss_per_class = (\n",
    "        (ms_cumsum_loss_per_class / (ms_count_per_class + 1)).cpu().numpy()\n",
    "    )\n",
    "    total_loss = ms_loss_per_class.mean(axis=1).sum()\n",
    "\n",
    "    with open(os.path.join(args.savedir, args.name, \"val_loss.txt\"), \"a\") as f:\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\n",
    "            \"{},\".format(epoch)\n",
    "            + \"{},\".format(float(total_loss))\n",
    "            + \"\".join(\"{},\".format(v) for v in ms_mean_iou)\n",
    "        )\n",
    "\n",
    "    with open(os.path.join(args.savedir, args.name, \"val_ious.txt\"), \"a\") as f:\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\n",
    "            \"Epoch: {},\\n\".format(epoch)\n",
    "            + \"Total Loss: {},\\n\".format(float(total_loss))\n",
    "            + \"\".join(\n",
    "                \"s{}_ious_per_class: {}, \\n\".format(s, v)\n",
    "                for s, v in zip(scales, ms_ious_per_class)\n",
    "            )\n",
    "            + \"\".join(\n",
    "                \"s{}_loss_per_class: {}, \\n\".format(s, v)\n",
    "                for s, v in zip(scales, ms_loss_per_class)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SrPJXFFmUUvS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704198394707,
     "user_tz": -420,
     "elapsed": 27,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     }
    }
   },
   "outputs": [],
   "source": [
    "def compute_loss(preds, labels, loss_name, args):\n",
    "\n",
    "    scale_idxs = torch.arange(len(preds)).int()\n",
    "\n",
    "    # Dice loss across classes at multiple scales\n",
    "    ms_loss = torch.stack(\n",
    "        [\n",
    "            src.model.loss.__dict__[loss_name](pred, label, idx_scale, args)\n",
    "            for pred, label, idx_scale in zip(preds, labels, scale_idxs)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if \"90\" not in args.model_name:\n",
    "        total_loss = torch.sum(ms_loss[3:]) + torch.mean(ms_loss[:3])\n",
    "    else:\n",
    "        total_loss = torch.sum(ms_loss)\n",
    "\n",
    "    # Store losses in dict\n",
    "    total_loss_dict = {\n",
    "        \"loss\": float(total_loss),\n",
    "    }\n",
    "\n",
    "    return total_loss, total_loss_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8yj2O2fDLxEJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704198394708,
     "user_tz": -420,
     "elapsed": 25,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     }
    }
   },
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    # ----------------------------- Data options ---------------------------- #\n",
    "    parser.add_argument(\n",
    "        \"--root\",\n",
    "        type=str,\n",
    "        default=\"nuseces_data\",\n",
    "        help=\"root directory of the dataset\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--nusc-version\", type=str, default=\"v1.0-trainval\", help=\"nuscenes version\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--occ-gt\",\n",
    "        type=str,\n",
    "        default=\"200down100up\",\n",
    "        help=\"occluded (occ) or unoccluded(unocc) ground truth maps\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gt-version\",\n",
    "        type=str,\n",
    "        default=\"\",\n",
    "        help=\"ground truth name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--train-split\", type=str, default=\"train_full\", help=\"ground truth name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--val-split\", type=str, default=\"val_full\", help=\"ground truth name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data-size\",\n",
    "        type=float,\n",
    "        default=1,\n",
    "        help=\"percentage of dataset to train on\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--load-classes-nusc\",\n",
    "        type=str,\n",
    "        nargs=14,\n",
    "        default=[\n",
    "            \"drivable_area\",\n",
    "            \"ped_crossing\",\n",
    "            \"walkway\",\n",
    "            \"carpark_area\",\n",
    "            \"road_segment\",\n",
    "            \"lane\",\n",
    "            \"bus\",\n",
    "            \"bicycle\",\n",
    "            \"car\",\n",
    "            \"construction_vehicle\",\n",
    "            \"motorcycle\",\n",
    "            \"trailer\",\n",
    "            \"truck\",\n",
    "            \"pedestrian\",\n",
    "            \"trafficcone\",\n",
    "            \"barrier\",\n",
    "        ],\n",
    "        help=\"Classes to load for NuScenes\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--pred-classes-nusc\",\n",
    "        type=str,\n",
    "        nargs=12,\n",
    "        default=[\n",
    "            \"drivable_area\",\n",
    "            \"ped_crossing\",\n",
    "            \"walkway\",\n",
    "            \"carpark_area\",\n",
    "            \"bus\",\n",
    "            \"bicycle\",\n",
    "            \"car\",\n",
    "            \"construction_vehicle\",\n",
    "            \"motorcycle\",\n",
    "            \"trailer\",\n",
    "            \"truck\",\n",
    "            \"pedestrian\",\n",
    "            \"trafficcone\",\n",
    "            \"barrier\",\n",
    "        ],\n",
    "        help=\"Classes to predict for NuScenes\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lidar-ray-mask\",\n",
    "        type=str,\n",
    "        default=\"dense\",\n",
    "        help=\"sparse or dense lidar ray visibility mask\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--grid-size\",\n",
    "        type=float,\n",
    "        nargs=2,\n",
    "        default=(50.0, 50.0),\n",
    "        help=\"width and depth of validation grid, in meters\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--z-intervals\",\n",
    "        type=float,\n",
    "        nargs=\"+\",\n",
    "        default=[1.0, 9.0, 21.0, 39.0, 51.0],\n",
    "        help=\"depths at which to predict BEV maps\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--grid-jitter\",\n",
    "        type=float,\n",
    "        nargs=3,\n",
    "        default=[0.0, 0.0, 0.0],\n",
    "        help=\"magn. of random noise applied to grid coords\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--aug-image-size\",\n",
    "        type=int,\n",
    "        nargs=\"+\",\n",
    "        default=[1280, 720],\n",
    "        help=\"size of random image crops during training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--desired-image-size\",\n",
    "        type=int,\n",
    "        nargs=\"+\",\n",
    "        default=[1600, 900],\n",
    "        help=\"size images are padded to before passing to network\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--yoffset\",\n",
    "        type=float,\n",
    "        default=1.74,\n",
    "        help=\"vertical offset of the grid from the camera axis\",\n",
    "    )\n",
    "\n",
    "    # -------------------------- Model options -------------------------- #\n",
    "    parser.add_argument(\n",
    "        \"--model-name\",\n",
    "        type=str,\n",
    "        default=\"PyrOccTranDetr_S_0904_old_rep100x100_out100x100\",\n",
    "        help=\"Model to train\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-r\",\n",
    "        \"--grid-res\",\n",
    "        type=float,\n",
    "        default=0.5,\n",
    "        help=\"size of grid cells, in meters\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--frontend\",\n",
    "        type=str,\n",
    "        default=\"resnet101\",\n",
    "        choices=[\"resnet18\", \"resnet34\", \"resnet50\"],\n",
    "        help=\"name of frontend ResNet architecture\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--pretrained\",\n",
    "        type=bool,\n",
    "        default=True,\n",
    "        help=\"choose pretrained frontend ResNet\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--pretrained-bem\",\n",
    "        type=bool,\n",
    "        default=False,\n",
    "        help=\"choose pretrained BEV estimation model\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--pretrained-model\",\n",
    "        type=str,\n",
    "        default=\"iccv_segdet_pyrocctrandetr_s_0904_100x100_200down100up_dice_adam_lr5e5_di3_1600x900\",\n",
    "        help=\"name of pretrained model to load\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--load-ckpt\",\n",
    "        type=str,\n",
    "        default=\"checkpoint-0020.pth.gz\",\n",
    "        help=\"name of checkpoint to load\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ignore\", type=str, default=[\"nothing\"], help=\"pretrained modules to ignore\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ignore-reload\",\n",
    "        type=str,\n",
    "        default=[\"nothing\"],\n",
    "        help=\"pretrained modules to ignore\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--focal-length\", type=float, default=1266.417, help=\"focal length\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--scales\",\n",
    "        type=float,\n",
    "        nargs=4,\n",
    "        default=[8.0, 16.0, 32.0, 64.0],\n",
    "        help=\"resnet frontend scale factor\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--cropped-height\",\n",
    "        type=float,\n",
    "        nargs=4,\n",
    "        default=[20.0, 20.0, 20.0, 20.0],\n",
    "        help=\"resnet feature maps cropped height\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--y-crop\",\n",
    "        type=float,\n",
    "        nargs=4,\n",
    "        default=[15, 15.0, 15.0, 15.0],\n",
    "        help=\"Max y-dimension in world space for all depth intervals\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dla-norm\",\n",
    "        type=str,\n",
    "        default=\"GroupNorm\",\n",
    "        help=\"Normalisation for inputs to topdown network\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--bevt-linear-additions\",\n",
    "        type=str2bool,\n",
    "        default=False,\n",
    "        help=\"BatchNorm, ReLU and Dropout addition to linear layer in BEVT\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--bevt-conv-additions\",\n",
    "        type=str2bool,\n",
    "        default=False,\n",
    "        help=\"BatchNorm, ReLU and Dropout addition to conv layer in BEVT\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dla-l1-nchannels\",\n",
    "        type=int,\n",
    "        default=64,\n",
    "        help=\"vertical offset of the grid from the camera axis\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--n-enc-layers\",\n",
    "        type=int,\n",
    "        default=2,\n",
    "        help=\"number of transfomer encoder layers\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--n-dec-layers\",\n",
    "        type=int,\n",
    "        default=2,\n",
    "        help=\"number of transformer decoder layers\",\n",
    "    )\n",
    "\n",
    "    # ---------------------------- Loss options ---------------------------- #\n",
    "    parser.add_argument(\n",
    "        \"--loss\", type=str, default=\"dice_loss_mean\", help=\"Loss function\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--exp-cf\",\n",
    "        type=float,\n",
    "        default=0.0,\n",
    "        help=\"Exponential for class frequency in weighted dice loss\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--exp-os\",\n",
    "        type=float,\n",
    "        default=0.2,\n",
    "        help=\"Exponential for object size in weighted dice loss\",\n",
    "    )\n",
    "\n",
    "    # ------------------------ Optimization options ----------------------- #\n",
    "    parser.add_argument(\"--optimizer\", type=str, default=\"adam\", help=\"optimizer\")\n",
    "    parser.add_argument(\"-l\", \"--lr\", type=float, default=5e-5, help=\"learning rate\")\n",
    "    parser.add_argument(\"--momentum\", type=float, default=0.9, help=\"momentum for SGD\")\n",
    "    parser.add_argument(\"--weight-decay\", type=float, default=1e-4, help=\"weight decay\")\n",
    "    parser.add_argument(\n",
    "        \"--lr-decay\",\n",
    "        type=float,\n",
    "        default=0.99,\n",
    "        help=\"factor to decay learning rate by every epoch\",\n",
    "    )\n",
    "\n",
    "    # ------------------------- Training options ------------------------- #\n",
    "    parser.add_argument(\n",
    "        \"-e\", \"--epochs\", type=int, default=40, help=\"number of epochs to train for\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-b\", \"--batch-size\", type=int, default=4, help=\"mini-batch size for training\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--accumulation-steps\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"Gradient accumulation over number of batches\",\n",
    "    )\n",
    "\n",
    "    # ------------------------ Experiment options ----------------------- #\n",
    "    parser.add_argument(\n",
    "        \"--name\", type=str,\n",
    "        default=\"tiim_old\",\n",
    "        help=\"name of experiment\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-s\",\n",
    "        \"--savedir\",\n",
    "        type=str,\n",
    "        default=\"experiments\",\n",
    "        help=\"directory to save experiments to\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-g\",\n",
    "        \"--gpu\",\n",
    "        type=int,\n",
    "        nargs=\"*\",\n",
    "        default=[0],\n",
    "        help=\"ids of gpus to train on. Leave empty to use cpu\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num-gpu\", type=int, default=1, help=\"number of gpus\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-w\",\n",
    "        \"--workers\",\n",
    "        type=int,\n",
    "        default=4,\n",
    "        help=\"number of worker threads to use for data loading\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--val-interval\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"number of epochs between validation runs\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--print-iter\",\n",
    "        type=int,\n",
    "        default=5,\n",
    "        help=\"print loss summary every N iterations\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--vis-iter\",\n",
    "        type=int,\n",
    "        default=20,\n",
    "        help=\"display visualizations every N iterations\",\n",
    "    )\n",
    "    return parser.parse_args(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5aneHbxgnoKp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704198394708,
     "user_tz": -420,
     "elapsed": 22,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     }
    }
   },
   "outputs": [],
   "source": [
    "def visualize_score(scores, heatmaps, grid, image, iou, num_classes):\n",
    "    # Condese scores and ground truths to single map\n",
    "    class_idx = torch.arange(len(scores)) + 1\n",
    "    logits = scores.clone().cpu() * class_idx.view(-1, 1, 1)\n",
    "    logits, _ = logits.max(dim=0)\n",
    "    scores = (scores.detach().clone().cpu() > 0.5).float() * class_idx.view(-1, 1, 1)\n",
    "    scores, _ = scores.max(dim=0)\n",
    "    heatmaps = (heatmaps.detach().clone().cpu() > 0.5).float() * class_idx.view(\n",
    "        -1, 1, 1\n",
    "    )\n",
    "    heatmaps, _ = heatmaps.max(dim=0)\n",
    "\n",
    "    # Visualize score\n",
    "    fig = plt.figure(num=\"score\", figsize=(8, 6))\n",
    "    fig.clear()\n",
    "\n",
    "    gs = mpl.gridspec.GridSpec(2, 3, figure=fig)\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    ax3 = fig.add_subplot(gs[1:, 1])\n",
    "    ax4 = fig.add_subplot(gs[1:, 2])\n",
    "\n",
    "    image = ax1.imshow(image)\n",
    "    ax1.grid(which=\"both\")\n",
    "    src.visualization.encoded.vis_score_raw(logits, grid, cmap=\"magma\", ax=ax2)\n",
    "    src.vis_score(scores, grid, cmap=\"magma\", ax=ax3, num_classes=num_classes)\n",
    "    src.vis_score(heatmaps, grid, cmap=\"magma\", ax=ax4, num_classes=num_classes)\n",
    "\n",
    "    grid = grid.cpu().detach().numpy()\n",
    "    yrange = np.arange(grid[:, 0].max(), step=5)\n",
    "    xrange = np.arange(start=grid[0, :].min(), stop=grid[0, :].max(), step=5)\n",
    "    ymin, ymax = 0, grid[:, 0].max()\n",
    "    xmin, xmax = grid[0, :].min(), grid[0, :].max()\n",
    "\n",
    "    ax2.vlines(xrange, ymin, ymax, color=\"white\", linewidth=0.5)\n",
    "    ax2.hlines(yrange, xmin, xmax, color=\"white\", linewidth=0.5)\n",
    "    ax3.vlines(xrange, ymin, ymax, color=\"white\", linewidth=0.5)\n",
    "    ax3.hlines(yrange, xmin, xmax, color=\"white\", linewidth=0.5)\n",
    "    ax4.vlines(xrange, ymin, ymax, color=\"white\", linewidth=0.5)\n",
    "    ax4.hlines(yrange, xmin, xmax, color=\"white\", linewidth=0.5)\n",
    "\n",
    "    ax1.set_title(\"Input image\", size=11)\n",
    "    ax2.set_title(\"Model output logits\", size=11)\n",
    "    ax3.set_title(\"Model prediction = logits\" + r\"$ > 0.5$\", size=11)\n",
    "    ax4.set_title(\"Ground truth\", size=11)\n",
    "\n",
    "    # plt.suptitle(\n",
    "    #     \"IoU : {:.2f}\".format(iou), size=14,\n",
    "    # )\n",
    "\n",
    "    gs.tight_layout(fig)\n",
    "    gs.update(top=0.9)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vn5KJE9IL1No",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704198394709,
     "user_tz": -420,
     "elapsed": 21,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     }
    }
   },
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in (\"yes\", \"true\", \"t\", \"y\", \"1\"):\n",
    "        return True\n",
    "    elif v.lower() in (\"no\", \"false\", \"f\", \"n\", \"0\"):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError(\"Boolean value expected.\")\n",
    "\n",
    "\n",
    "def _make_experiment(args):\n",
    "    print(\"\\n\" + \"#\" * 80)\n",
    "    # print(datetime.now().strftime(\"%A %-d %B %Y %H:%M\"))\n",
    "    print(\n",
    "        \"Creating experiment '{}' in directory:\\n  {}\".format(args.name, args.savedir)\n",
    "    )\n",
    "    print(\"#\" * 80)\n",
    "    print(\"\\nConfig:\")\n",
    "    for key in sorted(args.__dict__):\n",
    "        print(\"  {:12s} {}\".format(key + \":\", args.__dict__[key]))\n",
    "    print(\"#\" * 80)\n",
    "\n",
    "    # Create a new directory for the experiment\n",
    "    savedir = os.path.join(args.savedir, args.name)\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "    # # Create tensorboard summary writer\n",
    "    summary = SummaryWriter(savedir)\n",
    "\n",
    "    # # Save configuration to file\n",
    "    with open(os.path.join(savedir, \"config.txt\"), \"w\") as fp:\n",
    "        json.dump(args.__dict__, fp)\n",
    "\n",
    "    # # Write config as a text summary\n",
    "    # summary.add_text(\n",
    "    #     \"config\",\n",
    "    #     \"\\n\".join(\"{:12s} {}\".format(k, v) for k, v in sorted(args.__dict__.items())),\n",
    "    # )\n",
    "    # summary.file_writer.flush()\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_checkpoint(args, epoch, model, optimizer, scheduler):\n",
    "    ckpt = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optim\": optimizer.state_dict(),\n",
    "        \"scheduler\": scheduler.state_dict(),\n",
    "    }\n",
    "    ckpt_file = os.path.join(\n",
    "        args.savedir, args.name, \"checkpoint-{:04d}.pth.gz\".format(epoch)\n",
    "    )\n",
    "    print(\"==> Saving checkpoint '{}'\".format(ckpt_file))\n",
    "    torch.save(ckpt, ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "k0DiLDmQ1fA9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704198394709,
     "user_tz": -420,
     "elapsed": 20,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     }
    }
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process()\n",
    "    return process.memory_info().rss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AjolNJRgUh_x",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704198394709,
     "user_tz": -420,
     "elapsed": 19,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     }
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Parse command line arguments\n",
    "    args = parse_args()\n",
    "    print(args.root)\n",
    "    # args.root = os.path.join(os.getcwd(), args.root)\n",
    "    args.savedir = os.path.join(os.getcwd(), args.savedir)\n",
    "    print(args.savedir)\n",
    "\n",
    "    # Build depth intervals along Z axis and reverse\n",
    "    # z intervals: Độ sâu để dự đoán bản đồ BEV\n",
    "    z_range = args.z_intervals\n",
    "    args.grid_size = (z_range[-1] - z_range[0], z_range[-1] - z_range[0])\n",
    "\n",
    "    # Calculate cropped heights of feature maps\n",
    "    # Tính chiều cao đã cắt của bản đồ đối tượng địa lý\n",
    "    h_cropped = src.utils.calc_cropped_heights(\n",
    "        args.focal_length, np.array(args.y_crop), z_range, args.scales\n",
    "    )\n",
    "    args.cropped_height = [h for h in h_cropped]\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    args.num_gpu = num_gpus\n",
    "\n",
    "    ### Create experiment ###\n",
    "    summary = _make_experiment(args)\n",
    "\n",
    "    print(\"loading train data\")\n",
    "    # Create datasets\n",
    "    train_data = nuScenesMaps(\n",
    "        root=args.root,\n",
    "        split=args.train_split,\n",
    "        grid_size=args.grid_size,\n",
    "        grid_res=args.grid_res,\n",
    "        classes=args.load_classes_nusc,\n",
    "        dataset_size=args.data_size,\n",
    "        desired_image_size=args.desired_image_size,\n",
    "        mini=False,\n",
    "        gt_out_size=(100, 100),\n",
    "    )\n",
    "\n",
    "    print(\"loading val data\")\n",
    "    val_data = nuScenesMaps(\n",
    "        root=args.root,\n",
    "        split=args.val_split,\n",
    "        grid_size=args.grid_size,\n",
    "        grid_res=args.grid_res,\n",
    "        classes=args.load_classes_nusc,\n",
    "        dataset_size=args.data_size,\n",
    "        desired_image_size=args.desired_image_size,\n",
    "        mini=False,\n",
    "        gt_out_size=(200, 200),\n",
    "    )\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        collate_fn=src.data.collate_funcs.collate_nusc_s,\n",
    "        drop_last=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=1,\n",
    "        collate_fn=src.data.collate_funcs.collate_nusc_s,\n",
    "        drop_last=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Build model\n",
    "    model = networks.__dict__[args.model_name](\n",
    "        num_classes=len(args.pred_classes_nusc), ## Classes to predict for NuScenes\n",
    "        frontend=args.frontend, ## name of frontend ResNet architecture resnet18\", \"resnet34\", \"resnet50 default=\"resnet50\",\n",
    "        grid_res=args.grid_res, ## size of grid cells, in meters default=0.5,\n",
    "        pretrained=args.pretrained, ## choose pretrained frontend ResNet default=True,\n",
    "        img_dims=args.desired_image_size, ## kích thước hình ảnh được đệm trước khi chuyển sang mạng default=[1600, 900],\n",
    "        z_range=z_range,\n",
    "        h_cropped=args.cropped_height, ## resnet feature maps cropped height\n",
    "        dla_norm=args.dla_norm, ## Normalisation for inputs to topdown network default=\"GroupNorm\",\n",
    "        additions_BEVT_linear=args.bevt_linear_additions, ## BatchNorm, ReLU and Dropout addition to linear layer in BEVT default=False,\n",
    "        additions_BEVT_conv=args.bevt_conv_additions, ## BatchNorm, ReLU and Dropout addition to conv layer in BEVT default=False,\n",
    "        dla_l1_n_channels=args.dla_l1_nchannels, ## vertical offset of the grid from the camera axis độ lệch dọc của lưới từ trục máy ảnh default=64,\n",
    "        n_enc_layers=args.n_enc_layers, ## số lớp mã hóa máy biến áp number of transfomer encoder layers default=2,\n",
    "        n_dec_layers=args.n_dec_layers, # number of transformer decoder layers default=2,\n",
    "    )\n",
    "\n",
    "    if args.pretrained_bem: ## chọn mô hình ước tính BEV được đào tạo trước\n",
    "        pretrained_model_dir = os.path.join(args.savedir, args.pretrained_model) ## pretrained_model: tên của mô hình được đào tạo trước để tải\n",
    "        # pretrained_ckpt_fn = sorted(\n",
    "        #     [\n",
    "        #         f\n",
    "        #         for f in os.listdir(pretrained_model_dir)\n",
    "        #         if os.path.isfile(os.path.join(pretrained_model_dir, f))\n",
    "        #         and \".pth.gz\" in f\n",
    "        #     ]\n",
    "        # )\n",
    "        pretrained_pth = os.path.join(pretrained_model_dir, args.load_ckpt)\n",
    "        pretrained_dict = torch.load(pretrained_pth)[\"model\"]\n",
    "        mod_dict = OrderedDict()\n",
    "\n",
    "        # # Remove \"module\" from name\n",
    "        for k, v in pretrained_dict.items():\n",
    "            if any(module in k for module in args.ignore):\n",
    "                continue\n",
    "            else:\n",
    "                name = k[7:]\n",
    "                mod_dict[name] = v\n",
    "\n",
    "        model.load_state_dict(mod_dict, strict=False)\n",
    "        print(\"loaded pretrained model\")\n",
    "\n",
    "    device = torch.device(\"cuda\") ##  định vị thiết bị GPU\n",
    "    model = nn.DataParallel(model) ## tăng tốc độ huấn luyện mô hình trên nhiều GPU\n",
    "    model.to(device)\n",
    "\n",
    "    # Setup optimizer\n",
    "    if args.optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), args.lr, )\n",
    "    else:\n",
    "        optimizer = optim.__dict__[args.optimizer](\n",
    "            model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
    "        )\n",
    "\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, args.lr_decay)\n",
    "\n",
    "    # Check if saved model checkpoint exists\n",
    "    model_dir = os.path.join(args.savedir, args.name)\n",
    "    print(model_dir)\n",
    "    checkpt_fn = sorted(\n",
    "        [\n",
    "            f\n",
    "            for f in os.listdir(model_dir)\n",
    "            if os.path.isfile(os.path.join(model_dir, f)) and \".pth.gz\" in f\n",
    "        ]\n",
    "    )\n",
    "    print(len(checkpt_fn))\n",
    "    if len(checkpt_fn) != 0:\n",
    "        model_pth = os.path.join(model_dir, checkpt_fn[-1])\n",
    "        ckpt = torch.load(model_pth)\n",
    "        model.load_state_dict(ckpt[\"model\"])\n",
    "        optimizer.load_state_dict(ckpt[\"optim\"])\n",
    "        scheduler.load_state_dict(ckpt[\"scheduler\"])\n",
    "        epoch_ckpt = ckpt[\"epoch\"] + 1\n",
    "        print(\"starting training from {}\".format(checkpt_fn[-1]))\n",
    "    else:\n",
    "        epoch_ckpt = 1\n",
    "        pass\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "\n",
    "    for epoch in range(epoch_ckpt, args.epochs + 1):\n",
    "\n",
    "        print(\"\\n=== Beginning epoch {} of {} ===\".format(epoch, args.epochs))\n",
    "\n",
    "        # # Train model\n",
    "        train(args, train_loader, model, optimizer, epoch)\n",
    "\n",
    "        # Run validation every N epochs\n",
    "        if epoch % args.val_interval == 0:\n",
    "            # Save model checkpoint\n",
    "            save_checkpoint(args, epoch, model, optimizer, scheduler)\n",
    "            validate(args, val_loader, model, epoch)\n",
    "\n",
    "        # Update and log learning rate\n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CZAIVZWeYuZf",
    "outputId": "e9142197-97cf-442a-eaa1-cd13d86db856",
    "executionInfo": {
     "status": "error",
     "timestamp": 1704198495672,
     "user_tz": -420,
     "elapsed": 100980,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nuseces_data\n",
      "/content/gdrive/.shortcut-targets-by-id/1POdiPpRQ9jOyxG747glU_7Umrq_XkMmg/FA23_DatTriQuynh/Code/experiments\n",
      "\n",
      "################################################################################\n",
      "Creating experiment 'tiim_old' in directory:\n",
      "  /content/gdrive/.shortcut-targets-by-id/1POdiPpRQ9jOyxG747glU_7Umrq_XkMmg/FA23_DatTriQuynh/Code/experiments\n",
      "################################################################################\n",
      "\n",
      "Config:\n",
      "  accumulation_steps: 1\n",
      "  aug_image_size: [1280, 720]\n",
      "  batch_size:  4\n",
      "  bevt_conv_additions: False\n",
      "  bevt_linear_additions: False\n",
      "  cropped_height: [93.0, 61.0, 57.0, 66.0]\n",
      "  data_size:   1\n",
      "  desired_image_size: [1600, 900]\n",
      "  dla_l1_nchannels: 64\n",
      "  dla_norm:    GroupNorm\n",
      "  epochs:      40\n",
      "  exp_cf:      0.0\n",
      "  exp_os:      0.2\n",
      "  focal_length: 1266.417\n",
      "  frontend:    resnet101\n",
      "  gpu:         [0]\n",
      "  grid_jitter: [0.0, 0.0, 0.0]\n",
      "  grid_res:    0.5\n",
      "  grid_size:   (50.0, 50.0)\n",
      "  gt_version:  \n",
      "  ignore:      ['nothing']\n",
      "  ignore_reload: ['nothing']\n",
      "  lidar_ray_mask: dense\n",
      "  load_ckpt:   checkpoint-0020.pth.gz\n",
      "  load_classes_nusc: ['drivable_area', 'ped_crossing', 'walkway', 'carpark_area', 'road_segment', 'lane', 'bus', 'bicycle', 'car', 'construction_vehicle', 'motorcycle', 'trailer', 'truck', 'pedestrian', 'trafficcone', 'barrier']\n",
      "  loss:        dice_loss_mean\n",
      "  lr:          5e-05\n",
      "  lr_decay:    0.99\n",
      "  model_name:  PyrOccTranDetr_S_0904_old_rep100x100_out100x100\n",
      "  momentum:    0.9\n",
      "  n_dec_layers: 2\n",
      "  n_enc_layers: 2\n",
      "  name:        tiim_old\n",
      "  num_gpu:     1\n",
      "  nusc_version: v1.0-trainval\n",
      "  occ_gt:      200down100up\n",
      "  optimizer:   adam\n",
      "  pred_classes_nusc: ['drivable_area', 'ped_crossing', 'walkway', 'carpark_area', 'bus', 'bicycle', 'car', 'construction_vehicle', 'motorcycle', 'trailer', 'truck', 'pedestrian', 'trafficcone', 'barrier']\n",
      "  pretrained:  True\n",
      "  pretrained_bem: False\n",
      "  pretrained_model: iccv_segdet_pyrocctrandetr_s_0904_100x100_200down100up_dice_adam_lr5e5_di3_1600x900\n",
      "  print_iter:  5\n",
      "  root:        nuseces_data\n",
      "  savedir:     /content/gdrive/.shortcut-targets-by-id/1POdiPpRQ9jOyxG747glU_7Umrq_XkMmg/FA23_DatTriQuynh/Code/experiments\n",
      "  scales:      [8.0, 16.0, 32.0, 64.0]\n",
      "  train_split: train_full\n",
      "  val_interval: 1\n",
      "  val_split:   val_full\n",
      "  vis_iter:    20\n",
      "  weight_decay: 0.0001\n",
      "  workers:     4\n",
      "  y_crop:      [15, 15.0, 15.0, 15.0]\n",
      "  yoffset:     1.74\n",
      "  z_intervals: [1.0, 9.0, 21.0, 39.0, 51.0]\n",
      "################################################################################\n",
      "loading train data\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading val data\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-15-972361fa1b80>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"__main__\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-14-c533883a2df9>\u001B[0m in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m     \u001B[0;31m# Build model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 74\u001B[0;31m     model = networks.__dict__[args.model_name](\n\u001B[0m\u001B[1;32m     75\u001B[0m         \u001B[0mnum_classes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpred_classes_nusc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;31m## Classes to predict for NuScenes\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m         \u001B[0mfrontend\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrontend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;31m## name of frontend ResNet architecture resnet18\", \"resnet34\", \"resnet50 default=\"resnet50\",\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/gdrive/.shortcut-targets-by-id/1POdiPpRQ9jOyxG747glU_7Umrq_XkMmg/FA23_DatTriQuynh/Code/src/model/network.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, num_classes, frontend, grid_res, pretrained, img_dims, z_range, h_cropped, dla_norm, additions_BEVT_linear, additions_BEVT_conv, dla_l1_n_channels, n_enc_layers, n_dec_layers)\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m         \u001B[0;31m# Construct frontend network\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 60\u001B[0;31m         self.frontend = resnet_fpn_backbone(\n\u001B[0m\u001B[1;32m     61\u001B[0m             \u001B[0mbackbone_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfrontend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpretrained\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpretrained\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m         )\n",
      "\u001B[0;32m/content/gdrive/.shortcut-targets-by-id/1POdiPpRQ9jOyxG747glU_7Umrq_XkMmg/FA23_DatTriQuynh/Code/src/model/backbone_utils.py\u001B[0m in \u001B[0;36mresnet_fpn_backbone\u001B[0;34m(backbone_name, pretrained)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mresnet_fpn_backbone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbackbone_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpretrained\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m     backbone = resnet.__dict__[backbone_name](\n\u001B[0m\u001B[1;32m     48\u001B[0m         \u001B[0mpretrained\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpretrained\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnorm_layer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmisc_nn_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mFrozenBatchNorm2d\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m     )\n",
      "\u001B[0;31mKeyError\u001B[0m: 'resnet101'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzQTVNahblnd",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704198495674,
     "user_tz": -420,
     "elapsed": 25,
     "user": {
      "displayName": "Đạt Nguyễn Tiến",
      "userId": "01694367663357480799"
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
